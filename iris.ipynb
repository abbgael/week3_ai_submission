# AI Tools Assignment - Complete Solution
# Theme: "Mastering the AI Toolkit"

import warnings
warnings.filterwarnings('ignore')

# ============================================================================
# PART 2: PRACTICAL IMPLEMENTATION
# ============================================================================

# Task 1: Classical ML with Scikit-learn (Iris Dataset)
print("=" * 60)
print("TASK 1: IRIS CLASSIFICATION WITH SCIKIT-LEARN")
print("=" * 60)

from sklearn import datasets
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score, precision_score, recall_score, classification_report
import pandas as pd
import numpy as np

# Load and preprocess Iris dataset
iris = datasets.load_iris()
X, y = iris.data, iris.target

# Split data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Train Decision Tree Classifier
dt_classifier = DecisionTreeClassifier(random_state=42)
dt_classifier.fit(X_train, y_train)

# Make predictions
y_pred = dt_classifier.predict(X_test)

# Evaluate model
accuracy = accuracy_score(y_test, y_pred)
precision = precision_score(y_test, y_pred, average='weighted')
recall = recall_score(y_test, y_pred, average='weighted')

print(f"Accuracy: {accuracy:.4f}")
print(f"Precision: {precision:.4f}")
print(f"Recall: {recall:.4f}")
print("\nDetailed Classification Report:")
print(classification_report(y_test, y_pred, target_names=iris.target_names))

# ============================================================================
# Task 2: Deep Learning with TensorFlow (MNIST)
print("\n" + "=" * 60)
print("TASK 2: MNIST CNN WITH TENSORFLOW")
print("=" * 60)

import tensorflow as tf
from tensorflow import keras
import matplotlib.pyplot as plt

# Load and preprocess MNIST data
(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()

# Normalize pixel values
x_train = x_train.astype('float32') / 255.0
x_test = x_test.astype('float32') / 255.0

# Reshape for CNN (add channel dimension)
x_train = x_train.reshape(-1, 28, 28, 1)
x_test = x_test.reshape(-1, 28, 28, 1)

# Build CNN model
model = keras.Sequential([
    keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),
    keras.layers.MaxPooling2D((2, 2)),
    keras.layers.Conv2D(64, (3, 3), activation='relu'),
    keras.layers.MaxPooling2D((2, 2)),
    keras.layers.Flatten(),
    keras.layers.Dense(64, activation='relu'),
    keras.layers.Dense(10, activation='softmax')
])

# Compile model
model.compile(optimizer='adam',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])

print("Model Architecture:")
model.summary()

# Train model
print("\nTraining CNN model...")
history = model.fit(x_train, y_train, 
                   epochs=5, 
                   batch_size=128,
                   validation_split=0.1,
                   verbose=1)

# Evaluate model
test_loss, test_accuracy = model.evaluate(x_test, y_test, verbose=0)
print(f"\nTest Accuracy: {test_accuracy:.4f}")

# Visualize predictions on 5 sample images
predictions = model.predict(x_test[:5])
predicted_classes = np.argmax(predictions, axis=1)

print("\nPredictions on 5 sample images:")
for i in range(5):
    print(f"Image {i+1}: Predicted={predicted_classes[i]}, Actual={y_test[i]}")

# Note: In Jupyter notebook, you would add:
# plt.figure(figsize=(15, 3))
# for i in range(5):
#     plt.subplot(1, 5, i+1)
#     plt.imshow(x_test[i].reshape(28, 28), cmap='gray')
#     plt.title(f'Pred: {predicted_classes[i]}, True: {y_test[i]}')
#     plt.axis('off')
# plt.show()

# ============================================================================
# Task 3: NLP with spaCy
print("\n" + "=" * 60)
print("TASK 3: NLP WITH SPACY")
print("=" * 60)

import spacy

# Load spaCy model (install with: python -m spacy download en_core_web_sm)
try:
    nlp = spacy.load("en_core_web_sm")
except OSError:
    print("Please install spaCy English model: python -m spacy download en_core_web_sm")
    nlp = None

if nlp:
    # Sample Amazon product reviews
    reviews = [
        "The iPhone 14 from Apple is amazing! Great camera quality and battery life.",
        "Samsung Galaxy S23 is terrible. Poor build quality and overpriced.",
        "Love my MacBook Pro! Apple really knows how to make quality laptops.",
        "This Nike Air Max shoes are comfortable but expensive for the quality.",
        "Sony WH-1000XM4 headphones have excellent noise cancellation. Highly recommend!"
    ]
    
    # Process each review
    for i, review in enumerate(reviews, 1):
        print(f"\nReview {i}: {review}")
        doc = nlp(review)
        
        # Named Entity Recognition
        print("Entities found:")
        for ent in doc.ents:
            if ent.label_ in ['ORG', 'PRODUCT', 'PERSON']:  # Focus on brands/products
                print(f"  - {ent.text} ({ent.label_})")
        
        # Simple rule-based sentiment analysis
        positive_words = ['amazing', 'great', 'love', 'excellent', 'comfortable', 'quality', 'recommend']
        negative_words = ['terrible', 'poor', 'overpriced', 'expensive', 'bad', 'awful']
        
        text_lower = review.lower()
        pos_count = sum(1 for word in positive_words if word in text_lower)
        neg_count = sum(1 for word in negative_words if word in text_lower)
        
        if pos_count > neg_count:
            sentiment = "Positive"
        elif neg_count > pos_count:
            sentiment = "Negative"
        else:
            sentiment = "Neutral"
        
        print(f"Sentiment: {sentiment} (Pos: {pos_count}, Neg: {neg_count})")
        print("-" * 50)

# ============================================================================
# BONUS: Simple Streamlit Web App Code
print("\n" + "=" * 60)
print("BONUS: STREAMLIT WEB APP CODE")
print("=" * 60)

streamlit_code = '''
# streamlit_mnist_app.py
# Run with: streamlit run streamlit_mnist_app.py

import streamlit as st
import tensorflow as tf
import numpy as np
from PIL import Image

# Load trained model (save it first with model.save('mnist_model.h5'))
@st.cache_resource
def load_model():
    return tf.keras.models.load_model('mnist_model.h5')

st.title("MNIST Digit Classifier")
st.write("Upload an image of a handwritten digit (0-9)")

uploaded_file = st.file_uploader("Choose an image...", type=['png', 'jpg', 'jpeg'])

if uploaded_file is not None:
    # Load and preprocess image
    image = Image.open(uploaded_file).convert('L')  # Convert to grayscale
    image = image.resize((28, 28))
    img_array = np.array(image) / 255.0
    img_array = img_array.reshape(1, 28, 28, 1)
    
    # Display image
    st.image(image, caption='Uploaded Image', width=200)
    
    # Make prediction
    model = load_model()
    prediction = model.predict(img_array)
    predicted_digit = np.argmax(prediction)
    confidence = np.max(prediction)
    
    st.write(f"Predicted Digit: **{predicted_digit}**")
    st.write(f"Confidence: **{confidence:.2%}**")
'''

print("Streamlit app code saved above. Save as 'streamlit_mnist_app.py'")
print("Run with: streamlit run streamlit_mnist_app.py")

print("\n" + "=" * 60)
print("ALL TASKS COMPLETED!")
print("=" * 60)
print("✅ Task 1: Iris classification with Decision Tree")
print("✅ Task 2: MNIST CNN with >95% accuracy target")
print("✅ Task 3: NLP with spaCy for NER and sentiment")
print("✅ Bonus: Streamlit web app code provided")
